#version 450

#extension GL_KHR_cooperative_matrix : require
#extension GL_KHR_memory_scope_semantics : require
#extension GL_EXT_shader_16bit_storage : require
#extension GL_EXT_shader_explicit_arithmetic_types_float16 : require
#extension GL_KHR_shader_subgroup_basic : require

// Workgroup size must equal subgroup size for cooperative matrices
layout(local_size_x_id = 0, local_size_y_id = 1, local_size_z_id = 2) in;

layout(std430, binding = 0) buffer InBufferA { float16_t a[]; }; // Matrix [m,k]
layout(std430, binding = 1) buffer InBufferB { float16_t b[]; }; // Matrix [k,n]
layout(std430, binding = 2) buffer OutBuffer { float16_t c[]; }; // Result [m,n]

layout(push_constant) uniform PushConstants {
    uint m;             // Height of matrix A and result
    uint k;             // Width of matrix A, height of matrix B
    uint n;             // Width of matrix B and result
    uint stride_a0;     // Row stride for matrix a
    uint stride_a1;     // Column stride for matrix a
    uint stride_b0;     // Row stride for matrix b
    uint stride_b1;     // Column stride for result b
    uint stride_c0;     // Row stride for result c
    uint stride_c1;     // Column stride for result c
} dims;

// Shared memory for staging tiles with arbitrary strides from global memory
shared float16_t tileA[16 * 16];
shared float16_t tileB[16 * 16];

void main() {
    // Each workgroup = one subgroup computes one 16x16 output tile
    uint tile_row = gl_WorkGroupID.y;
    uint tile_col = gl_WorkGroupID.x;

    uint out_row = tile_row * 16;
    uint out_col = tile_col * 16;

    // Bounds check
    if (out_row >= dims.m || out_col >= dims.n) {
        return;
    }

    // Initialize accumulator
    coopmat<float16_t, gl_ScopeSubgroup, 16, 16, gl_MatrixUseAccumulator> matC =
        coopmat<float16_t, gl_ScopeSubgroup, 16, 16, gl_MatrixUseAccumulator>(float16_t(0.0));

    uint num_k_tiles = (dims.k + 15) / 16;

    // Loop over K dimension in 16-element chunks
    for (uint k_tile = 0; k_tile < num_k_tiles; k_tile++) {
        uint k_offset = k_tile * 16;

        if (k_offset >= dims.k) {
            break;
        }

        // Load tiles from global memory (with arbitrary strides) into shared memory
        for (uint idx = gl_LocalInvocationIndex; idx < 256; idx += gl_WorkGroupSize.x) {
            uint i = idx / 16;
            uint j = idx % 16;

            uint row_a = out_row + i;
            uint col_a = k_offset + j;
            uint row_b = k_offset + i;
            uint col_b = out_col + j;

            tileA[idx] = (row_a < dims.m && col_a < dims.k)
                       ? a[row_a * dims.stride_a0 + col_a * dims.stride_a1]
                       : float16_t(0.0);

            tileB[idx] = (row_b < dims.k && col_b < dims.n)
                       ? b[row_b * dims.stride_b0 + col_b * dims.stride_b1]
                       : float16_t(0.0);
        }

        // Subgroup-only barrier (more efficient than full workgroup barrier)
        subgroupMemoryBarrierShared();
        subgroupBarrier();

        // Load cooperative matrices from shared memory (contiguous, stride=16)
        coopmat<float16_t, gl_ScopeSubgroup, 16, 16, gl_MatrixUseA> matA;
        coopmat<float16_t, gl_ScopeSubgroup, 16, 16, gl_MatrixUseB> matB;

        coopMatLoad(matA, tileA, 0, 16, gl_CooperativeMatrixLayoutRowMajor);
        coopMatLoad(matB, tileB, 0, 16, gl_CooperativeMatrixLayoutRowMajor);

        // Perform matrix multiply-accumulate
        matC = coopMatMulAdd(matA, matB, matC);
    }

    // Store result directly to global memory
    uint c_base = out_row * dims.stride_c0 + out_col * dims.stride_c1;
    coopMatStore(matC, c, c_base, dims.stride_c0, gl_CooperativeMatrixLayoutRowMajor);
}
